{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a3461f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker\n",
    "from lexicalrichness import LexicalRichness\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from itertools import groupby\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b38674e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1298ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sentence_length(text):\n",
    "    sentences = re.split('[?|!|\\.]',text)\n",
    "    avg_sentence = np.mean(np.array([len(sentence) for sentence in sentences]))\n",
    "    return avg_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4b42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_length(text):\n",
    "    text_clean = re.sub(r\"[^\\w]+\", ' ', text)\n",
    "    avg_word = np.mean(np.array([len(word) for word in nltk.word_tokenize(text_clean)]))\n",
    "    return avg_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b663cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = ['ADJ','ADP','ADV','CONJ','DET','NOUN','NUM','PRT','PRON','VERB','.']\n",
    "def pos_num(text):\n",
    "    \n",
    "    noun = 0\n",
    "    pronoun = 0\n",
    "    adjective = 0\n",
    "    numeral = 0\n",
    "    verb = 0\n",
    "    adverb = 0\n",
    "    end = 0\n",
    "    comma = 0\n",
    "    question = 0\n",
    "    exclamation = 0\n",
    "    total = len(text.split())\n",
    "    tags = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    counts = Counter( tag for word,  tag in tags)\n",
    "    for tag in counts:\n",
    "        if tag == 'NN' or tag == 'NNS' or tag == 'NNP' or tag == 'NNPS':\n",
    "            noun+=counts[tag]\n",
    "        elif tag == 'PRP':\n",
    "            pronoun += counts[tag]\n",
    "        elif tag == 'JJ' or tag == 'JJR 'or tag == 'JJS':\n",
    "            adjective += counts[tag]\n",
    "        elif tag == 'CD':\n",
    "            numeral += counts[tag]\n",
    "        elif tag == 'VB' or tag == 'VBD' or tag == 'VBG' or tag == 'VBN' or tag == 'VBP' or tag == 'VBZ':\n",
    "            verb += counts[tag]\n",
    "        elif tag == 'RB' or tag == 'RBR' or tag == 'RBS':\n",
    "            adverb += counts[tag]\n",
    "        elif tag == '.':\n",
    "            end += counts[tag]\n",
    "        elif tag == ',':\n",
    "            comma += counts[tag]\n",
    "        elif tag == '?':\n",
    "            question += counts[tag]\n",
    "        elif tag == '!':\n",
    "            exclamation += counts[tag]\n",
    "    #return noun,pronoun,adjective,numeral,verb,adverb,end,comma,question,exclamation\n",
    "    return noun,pronoun,adjective,numeral,verb,adverb,end,comma\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "085fb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mispelling(text):\n",
    "    spell = SpellChecker()\n",
    "    text_clean = re.sub(r\"[^\\w]+\", ' ', text)\n",
    "    return len(spell.unknown(text_clean.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c45bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_word(text, num):\n",
    "    tmp = [] \n",
    "    words = text.split()\n",
    "    for i in range(len(words)-num+1):\n",
    "        tmp.append(words[i:i+num]) \n",
    "    return tmp\n",
    "def ngram_letter(text, num):\n",
    "    tmp = [] \n",
    "    words = text.split()\n",
    "    for i in range(len(words)-num+1):\n",
    "        tmp.append(words[i:i+num]) \n",
    "    return tmp\n",
    "def diff_ngram(text1, text2, num):\n",
    "    \n",
    "    a = ngram_word(text1, num)\n",
    "    b = ngram_word(text2, num) \n",
    "    \n",
    "    cnt = 0 \n",
    "    for i in a:\n",
    "        for j in b:\n",
    "            if i == j:\n",
    "                cnt += 1\n",
    "                #common.append(i)\n",
    "    if len(a) == 0:\n",
    "        return 100000\n",
    "    else:\n",
    "        return cnt/len(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99cc0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cos(text1,text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform(np.array([text1,text2])).toarray()\n",
    "    return cosine_similarity(tfidf)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e139939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def words(entry):\n",
    "    return filter(lambda w: len(w) > 0,\n",
    "                  [w.strip(\"0123456789!:,.?(){}[]\") for w in entry.split()])\n",
    "\n",
    "def yule(entry):\n",
    "    # yule's I measure (the inverse of yule's K measure)\n",
    "    # higher number is higher diversity - richer vocabulary\n",
    "    d = {}\n",
    "    stemmer = PorterStemmer()\n",
    "    for w in words(entry):\n",
    "        w = stemmer.stem(w).lower()\n",
    "        try:\n",
    "            d[w] += 1\n",
    "        except KeyError:\n",
    "            d[w] = 1\n",
    "\n",
    "    M1 = float(len(d))\n",
    "    M2 = sum([len(list(g))*(freq**2) for freq,g in groupby(sorted(d.values()))])\n",
    "\n",
    "    try:\n",
    "        return (M1*M1)/(M2-M1)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    \n",
    "# yule(data.pair1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53b8d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fea = np.zeros(feature_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "966cbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(text1,text2,feature_num):\n",
    "    input_fea = np.zeros(feature_num)\n",
    "    avgs1 = avg_sentence_length(text1)\n",
    "    avgs2 = avg_sentence_length(text2)\n",
    "    input_fea[0] = max(avgs1,avgs2)/min(avgs1,avgs2)\n",
    "    avgs1 = avg_word_length(text1)\n",
    "    avgs2 = avg_word_length(text2)\n",
    "    input_fea[1] = max(avgs1,avgs2)/min(avgs1,avgs2)\n",
    "    noun1,pronoun1,adjective1,numeral1,verb1,adverb1,end1,comma1 = pos_num(text1)\n",
    "    noun2,pronoun2,adjective2,numeral2,verb2,adverb2,end2,comma2 = pos_num(text2)\n",
    "    input_fea[2] = abs(noun1-noun2)\n",
    "    input_fea[3] = abs(pronoun1 - pronoun2)\n",
    "    input_fea[4] = abs(adjective1 - adjective2)\n",
    "    input_fea[5] = abs(numeral1-numeral2)\n",
    "    input_fea[6] = abs(verb1 - verb2)\n",
    "    input_fea[7] = abs(adverb1-adverb2)\n",
    "    input_fea[8] = abs(end1 - end2)\n",
    "    input_fea[9] = abs(comma1 - comma2)\n",
    "    mis1 = mispelling(text1)\n",
    "    mis2 = mispelling(text2)\n",
    "    input_fea[10] = abs(mis1 - mis2)\n",
    "    input_fea[11] = diff_ngram(text1, text2, 2)\n",
    "    input_fea[12] = diff_ngram(text1, text2, 3)\n",
    "    input_fea[13] = diff_ngram(text1, text2, 4)\n",
    "    input_fea[14] = tfidf_cos(text1,text2)\n",
    "    yule1 = yule(text1)\n",
    "    yule2 = yule(text2)\n",
    "    input_fea[15] = max(yule1,yule2)/min(yule1,yule2)\n",
    "    richness1 = LexicalRichness(text1).mtld(threshold=0.72)\n",
    "    richness2 = LexicalRichness(text2).mtld(threshold=0.72)\n",
    "    input_fea[16] = max(richness1,richness2)/min(richness1,richness2)\n",
    "    return input_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "edd6f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sameORnot(feature):\n",
    "    result = RF.predict(feature.reshape(1,-1))[0]\n",
    "    if result == 1:\n",
    "        print('The two texts are written by the same author')\n",
    "    elif result ==0:\n",
    "        print('The two texts are written by different authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb39a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55d052ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text_unseen_authors/text1.txt')\n",
    "text1 = f.read() \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53c892cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text_unseen_authors/text2.txt')\n",
    "text2 = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "154b9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text_unseen_authors/text3.txt')\n",
    "text3 = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf067fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text_unseen_authors/text4.txt')\n",
    "text4 = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c90592d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('text_unseen_authors/text5.txt')\n",
    "text5 = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41c254b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5789"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b4a40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = joblib.load('model/RF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1 text2 shakespeare\n",
    "# text3 Edgar Allan Poe\n",
    "# text5 text6 jk rowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5e9ec50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two texts are written by the same author\n"
     ]
    }
   ],
   "source": [
    "# same: text1 text2 shakespeare\n",
    "sameORnot(create_fea(text1,text2,feature_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c2a00f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two texts are written by different authors\n"
     ]
    }
   ],
   "source": [
    "# different: text2 shakespeare text3 Edgar Allan Poe\n",
    "sameORnot(create_fea(text2,text3,feature_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21892167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two texts are written by different authors\n"
     ]
    }
   ],
   "source": [
    "# different: text3 Edgar Allan Poe text4 JK Rowling\n",
    "sameORnot(create_fea(text3,text4,feature_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f42285c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two texts are written by the same author\n"
     ]
    }
   ],
   "source": [
    "# same: text4 text5 JK Rowling\n",
    "sameORnot(create_fea(text4,text5,feature_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60446a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
